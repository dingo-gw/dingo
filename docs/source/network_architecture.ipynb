{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f01028e-f89f-48cb-9a39-f1b6148eb80b",
   "metadata": {},
   "source": [
    "# Neural network architecture\n",
    "\n",
    "Dingo is based on a method called [Neural posterior estimation](https://arxiv.org/abs/1605.06376), see [here](sbi.md) for an introduction. A central object is the conditional neural density estimator, a deep neural network trained to represent the Bayesian posterior. This section describes the neural network architecture developed in {cite:p}`Dax:2021tsq`, and subsequently used in {cite:p}`Dax:2021myb`, {cite:p}`Dax:2022pxd` and {cite:p}`Wildberger:2022agw`. Note that Dingo can easily be extended to different architectures.\n",
    "\n",
    "## Neural spline flow with SVD compression\n",
    "The architecture consists of two compenents, the embedding network which compresses the high-dimensionl data to a lower dimensional feature vector, and the conditional normalizing flow which estimates the Bayesian posterior based on this feature vector. Both components are trained jointly and end-to-end with the objective descriped [here](sbi.md). The network can be build with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12202bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dingo.core.nn.nsf import create_nsf_with_rb_projection_embedding_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfe641",
   "metadata": {},
   "source": [
    "### Embedding network\n",
    "The embedding network compresses the high-dimensional conditioning information (consisting of frequency domain strain and PSD data). The first layer of this network is initialized with an [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition) matrix from a reduced basis built with non-noisy waveforms. This projection filters out the noise that is orthogonal to the signal manifold, and significantly simplifies the task for the neural network.\n",
    "\n",
    "The initial compression layer is followed by a sequence of residual blocks consisting of dense layers for further compression. Example kwargs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_kwargs = {\n",
    "    \"input_dims\": (2, 3, 8033),\n",
    "    \"output_dim\": 128,\n",
    "    \"hidden_dims\": [\n",
    "        1024, 1024, 1024, 1024, 1024, 1024, \\\n",
    "        512, 512, 512, 512, 512, 512, \\\n",
    "        256, 256, 256, 256, 256, 256, \\\n",
    "        128, 128, 128, 128, 128, 128\n",
    "    ],\n",
    "    \"activation\": \"elu\",\n",
    "    \"dropout\": 0.0,\n",
    "    \"batch_norm\": True,\n",
    "    \"svd\": {\n",
    "        \"num_training_samples\": 50000,\n",
    "        \"num_validation_samples\": 5000,\n",
    "        \"size\": 200,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1261fa",
   "metadata": {},
   "source": [
    "Here, `input_dims=(2, 3, 8033)` refers to the input dimension, for frequency domain data with `8033` frequency bins and `3` channels (real part, complex part, ASD) in `2` detectors. The embedding network compresses this to `output_dim=128` components. The SVD initialization is controlled with the `svd` argument, and the residual blocks are specified with `hidden_dims`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18525738",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Not all of these arguments have to be set in the configuration file when training dingo. For example, the `input_dims` argument is automatically filled in based on the specified domain information and number of detectors. Similarly, the `context_dim` of the flow (see below) is filled in based on the `output_dim` of the embedding network and the number of [GNPE](gnpe.md) proxies. See the [Dingo examples](https://github.com/dingo-gw/dingo/tree/main/examples) for the corresponding configuration files and training commands.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cddb1",
   "metadata": {},
   "source": [
    "### Flow\n",
    "We use the [neural spline flow](https://arxiv.org/abs/1906.04032) as a density estimator. This takes the output of the embedding network as context information and estimates the Bayesian posterior distribution. Example kwargs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0a5eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_kwargs = {\n",
    "    \"input_dim\": 15,\n",
    "    \"context_dim\": 129,\n",
    "    \"num_flow_steps\": 30,\n",
    "    \"base_transform_kwargs\": {\n",
    "        \"hidden_dim\": 512,\n",
    "        \"num_transform_blocks\": 5,\n",
    "        \"activation\": \"elu\",\n",
    "        \"dropout_probability\": 0.0,\n",
    "        \"batch_norm\": True,\n",
    "        \"num_bins\": 8,\n",
    "        \"base_transform_type\": \"rq-coupling\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24eb0d",
   "metadata": {},
   "source": [
    "This creates a neural spline flow with `input_dim=15` parameters, conditioned on a `129` dimensional context vector, corresponding to the `128` dimensional output of the embedding network and one [GNPE](gnpe.md) proxy variable. The neural spline flow consists of `num_flow_steps=30` layers, for which the transformation is specified with `base_transform_kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3455f052",
   "metadata": {},
   "outputs": [],
   "source": "nde = create_nsf_with_rb_projection_embedding_net(posterior_kwargs, embedding_kwargs)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
